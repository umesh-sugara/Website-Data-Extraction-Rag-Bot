{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the WebBot created to scrape a website content and later traning an Ai chatbot model on the scraped content. \n",
    "## Note: \n",
    "1. Either you can use already scraped data as well as vector database provided along with the file, otherwise if you always have the option to make your updated one.\n",
    "\n",
    "2. While running the scraping code, it will be better if you yourself interrupt the code after 2-3 minutes, otherwise it will keep scraping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Set to store visited URLs to avoid duplicates\n",
    "visited_urls = set()\n",
    "seen_texts = set()\n",
    "\n",
    "def extract_main_keyword(url):\n",
    "    \"\"\"Extract the main keyword from a URL, like 'botpenguin' from 'https://botpenguin.com'.\"\"\"\n",
    "    domain = urlparse(url).netloc\n",
    "    # Split domain by dots and select the second last part, which usually represents the main name\n",
    "    parts = domain.split('.')\n",
    "    if len(parts) > 1:\n",
    "        return parts[-2]  # Get the second last part as the main keyword\n",
    "    return domain\n",
    "\n",
    "def is_valid_url(url, main_keyword):\n",
    "    \"\"\"Check if a URL contains the main keyword, allowing subdomains and different TLDs.\"\"\"\n",
    "    return main_keyword in urlparse(url).netloc\n",
    "\n",
    "def get_all_links(url, soup, main_keyword):\n",
    "    \"\"\"Extract all links containing the main keyword.\"\"\"\n",
    "    links = []\n",
    "    for link in soup.find_all('a', href=True):\n",
    "        full_link = urljoin(url, link['href'])\n",
    "        # Check if the link is valid and belongs to the same keyword-based domain\n",
    "        if full_link not in visited_urls and is_valid_url(full_link, main_keyword):\n",
    "            links.append(full_link)\n",
    "    return links\n",
    "\n",
    "def extract_text(soup):\n",
    "    \"\"\"Extract text from all relevant tags except headers and footers.\"\"\"\n",
    "    # Remove header and footer elements\n",
    "    for header in soup.find_all(['header', 'footer']):\n",
    "        header.decompose()  # Remove the header/footer from the soup object\n",
    "\n",
    "    # Extract text from relevant tags\n",
    "    texts = []\n",
    "    for tag in soup.find_all(['p', 'div', 'span', 'li']):\n",
    "        text = tag.get_text(strip=True)\n",
    "        if text:  # Only add non-empty text\n",
    "            texts.append(text)\n",
    "    \n",
    "    return texts\n",
    "\n",
    "def remove_existing_file(file_name='output.txt'):\n",
    "    \"\"\"Remove the existing file if it exists.\"\"\"\n",
    "    if os.path.exists(file_name):\n",
    "        os.remove(file_name)\n",
    "        print(f\"{file_name} has been removed.\")\n",
    "\n",
    "def write_text_to_file(text, file_name='output.txt'):\n",
    "    \"\"\"Append text to a file.\"\"\"\n",
    "    with open(file_name, 'a', encoding='utf-8') as file:\n",
    "        file.write(text + '\\n')\n",
    "\n",
    "def scrape_page(url, main_keyword):\n",
    "    \"\"\"Extract desired data from the page without repeatedly scraping headers, footers, or already seen content.\"\"\"\n",
    "    print(f\"Scraping: {url}\")\n",
    "    heading = f\"URL : {url}\"\n",
    "    write_text_to_file(heading) \n",
    "    try:\n",
    "        # Add headers to mimic a browser request\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Exclude header, footer, or repetitive sections identified by classes or tags\n",
    "        for tag in soup(['footer', 'aside']):\n",
    "            tag.decompose()  # Remove these elements from the soup\n",
    "        \n",
    "        # Extract text from specific tags, avoiding duplicates\n",
    "        paragraphs = soup.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'ul', 'ol', 'li'])\n",
    "\n",
    "        for para in paragraphs:\n",
    "            text = para.get_text(strip=True)\n",
    "            # Skip if the text has been seen before to reduce repetition\n",
    "            if text and text not in seen_texts:\n",
    "                print(text)  # Optional: to see the text being processed\n",
    "                write_text_to_file(text)  # Append text to the file\n",
    "                seen_texts.add(text)  # Mark this text as seen\n",
    "\n",
    "        # Mark the URL as visited\n",
    "        visited_urls.add(url)\n",
    "\n",
    "        # Return all links found on the current page\n",
    "        return get_all_links(url, soup, main_keyword)\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error scraping {url}: {e}\")\n",
    "        return []\n",
    "\n",
    "def crawl_and_scrape(base_url):\n",
    "    \"\"\"Crawl the website starting from the base URL, scraping each page.\"\"\"\n",
    "    main_keyword = extract_main_keyword(base_url)\n",
    "    urls_to_scrape = set([base_url])\n",
    "\n",
    "    while urls_to_scrape:\n",
    "        # Get a URL to scrape\n",
    "        current_url = urls_to_scrape.pop()\n",
    "        \n",
    "        # Scrape the page and get new links\n",
    "        new_links = scrape_page(current_url, main_keyword)\n",
    "        \n",
    "        # Add new links to the queue for scraping\n",
    "        urls_to_scrape.update(new_links)\n",
    "\n",
    "        # Add a delay to avoid overwhelming the server\n",
    "        time.sleep(1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing Output.txt file will be loaded.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def CreateNewScrapeFile():\n",
    "   # Correct input handling\n",
    "    base_url = input(\"Enter the website URL (e.g., https://www.botpenguin.com): \").strip()\n",
    "\n",
    "    # Ensure the URL starts with http:// or https://\n",
    "    if not base_url.startswith(('http://', 'https://')):\n",
    "        base_url = 'https://' + base_url\n",
    "\n",
    "    # Remove the existing output file if it exists\n",
    "    remove_existing_file()\n",
    "\n",
    "    # Start the crawling and scraping process\n",
    "    crawl_and_scrape(base_url)\n",
    "\n",
    "\n",
    "def load_existing_ScrapedData():\n",
    "    print(\"Existing Output.txt file will be loaded.\")\n",
    "\n",
    "choice = input(\"Would you like to (1) Srape data from website or (2) load an existing one? Enter 1 or 2: \")\n",
    "    \n",
    "if choice == '1':\n",
    "    CreateNewScrapeFile()\n",
    "elif choice == '2':\n",
    "    load_existing_ScrapedData()\n",
    "else:\n",
    "    print(\"Invalid choice. Please enter 1 or 2.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here just installing, some neccessary modules, rest we will see on the way!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --quiet  langchain langchain-community langchainhub langchain-openai chromadb bs4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace your OpenAi Key in the below given placeholder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<Your OpenAi Key>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157842\n"
     ]
    }
   ],
   "source": [
    "# Using 'with' statement ensures the file is closed automatically\n",
    "with open('output.txt', 'r', encoding='utf-8') as file:\n",
    "    # Read the entire content of the file\n",
    "    content = file.read()\n",
    "\n",
    "# Print the content of the file\n",
    "print(len(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1058, which is longer than the specified 1000\n",
      "Created a chunk of size 1050, which is longer than the specified 1000\n",
      "Created a chunk of size 1305, which is longer than the specified 1000\n",
      "Created a chunk of size 1629, which is longer than the specified 1000\n",
      "Created a chunk of size 1273, which is longer than the specified 1000\n",
      "Created a chunk of size 1004, which is longer than the specified 1000\n",
      "Created a chunk of size 1475, which is longer than the specified 1000\n",
      "Created a chunk of size 1457, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "import re\n",
    "def split_with_character_text_splitter(content):\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\",\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len\n",
    "    )\n",
    "    return text_splitter.split_text(content)\n",
    "\n",
    "\n",
    "splits = split_with_character_text_splitter(content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['URL : https://www.botpenguin.com\\n'\n",
      " 'Why BotPenguinProductSolutionsPricingPartnersResources\\n'\n",
      " 'Why BotPenguin\\n'\n",
      " 'Product\\n'\n",
      " 'Solutions\\n'\n",
      " 'Pricing\\n'\n",
      " 'Partners\\n'\n",
      " 'Resources\\n'\n",
      " 'Engage, Converse and Convertyour visitors using AI Chatbot Agent\\n'\n",
      " 'Generate 10x more leads, solve up to 80% customer queries, engage 70% more '\n",
      " 'visitorsto earn 90% more revenue by automating business communication.\\n'\n",
      " 'URL : https://www.botpenguin.com/chatbot-pricing\\n'\n",
      " 'Honest, Transparent and AffordableChatbot pricing\\n'\n",
      " 'No hidden costNo Markup cost (Meta charges)Get started for FREEGet FREE '\n",
      " 'Green Tick Verification\\n'\n",
      " 'No hidden cost\\n'\n",
      " 'No Markup cost (Meta charges)\\n'\n",
      " 'Get started for FREE\\n'\n",
      " 'Get FREE Green Tick Verification\\n'\n",
      " 'Baby Plan\\n'\n",
      " '$0\\n'\n",
      " 'Messages1,000Conversations100Chatbot1\\n'\n",
      " 'Messages1,000\\n'\n",
      " 'Conversations100\\n'\n",
      " 'Chatbot1\\n'\n",
      " 'What do you get?',\n",
      " 'No Markup cost (Meta charges)\\n'\n",
      " 'Get started for FREE\\n'\n",
      " 'Get FREE Green Tick Verification\\n'\n",
      " 'Baby Plan\\n'\n",
      " '$0\\n'\n",
      " 'Messages1,000Conversations100Chatbot1\\n'\n",
      " 'Messages1,000\\n'\n",
      " 'Conversations100\\n'\n",
      " 'Chatbot1\\n'\n",
      " 'What do you get?\\n'\n",
      " 'Chatbot PlatformsWhatsappWebsiteTelegramFacebookInstagramChatGPT Integration '\n",
      " '(3.5 Turbo Model)Configure AI Bot personalityAI Bot Training on Your '\n",
      " 'Knowledge baseUnlimited Subscriber/leadsUnified InboxMulti LanguagesLive '\n",
      " 'ChatReports & AnalyticsVideos & Help Tutorials2048-bit SSL secure '\n",
      " 'connection\\n'\n",
      " 'Chatbot PlatformsWhatsappWebsiteTelegramFacebookInstagram\\n'\n",
      " 'Chatbot Platforms\\n'\n",
      " 'ChatGPT Integration (3.5 Turbo Model)\\n'\n",
      " 'Configure AI Bot personality\\n'\n",
      " 'AI Bot Training on Your Knowledge base\\n'\n",
      " 'Unlimited Subscriber/leads\\n'\n",
      " 'Unified Inbox\\n'\n",
      " 'Multi Languages\\n'\n",
      " 'Live Chat\\n'\n",
      " 'Reports & Analytics\\n'\n",
      " 'Videos & Help Tutorials\\n'\n",
      " '2048-bit SSL secure connection\\n'\n",
      " 'Little Plan\\n'\n",
      " '$15\\n'\n",
      " 'Messages3,000Conversations3,000Chatbot5Agents5\\n'\n",
      " 'Messages3,000\\n'\n",
      " 'Conversations3,000\\n'\n",
      " 'Chatbot5\\n'\n",
      " 'Agents5\\n'\n",
      " 'Everything in Baby Plan, Plus:',\n",
      " 'Videos & Help Tutorials\\n'\n",
      " '2048-bit SSL secure connection\\n'\n",
      " 'Little Plan\\n'\n",
      " '$15\\n'\n",
      " 'Messages3,000Conversations3,000Chatbot5Agents5\\n'\n",
      " 'Messages3,000\\n'\n",
      " 'Conversations3,000\\n'\n",
      " 'Chatbot5\\n'\n",
      " 'Agents5\\n'\n",
      " 'Everything in Baby Plan, Plus:\\n'\n",
      " 'Lead Notification on EmailAppointment BookingCustomer SegmentationCustom '\n",
      " 'Attributes & TagsDrip & Broadcast CampaignsMobile Apps for agentsOrder/Shop '\n",
      " 'ManagementCRM IntegrationsTicketing System IntegrationsWoo-commerce '\n",
      " 'IntegrationShopify Integration30+ Integrations\\n'\n",
      " 'Lead Notification on Email\\n'\n",
      " 'Appointment Booking\\n'\n",
      " 'Customer Segmentation\\n'\n",
      " 'Custom Attributes & Tags\\n'\n",
      " 'Drip & Broadcast Campaigns\\n'\n",
      " 'Mobile Apps for agents\\n'\n",
      " 'Order/Shop Management\\n'\n",
      " 'CRM Integrations\\n'\n",
      " 'Ticketing System Integrations\\n'\n",
      " 'Woo-commerce Integration\\n'\n",
      " 'Shopify Integration\\n'\n",
      " '30+ Integrations\\n'\n",
      " 'King Plan\\n'\n",
      " '$50\\n'\n",
      " 'Messages12,000Conversations12,000ChatbotUnlimitedAgents10\\n'\n",
      " 'Messages12,000\\n'\n",
      " 'Conversations12,000\\n'\n",
      " 'ChatbotUnlimited\\n'\n",
      " 'Agents10\\n'\n",
      " 'Everything in Little Plan, Plus:',\n",
      " '30+ Integrations\\n'\n",
      " 'King Plan\\n'\n",
      " '$50\\n'\n",
      " 'Messages12,000Conversations12,000ChatbotUnlimitedAgents10\\n'\n",
      " 'Messages12,000\\n'\n",
      " 'Conversations12,000\\n'\n",
      " 'ChatbotUnlimited\\n'\n",
      " 'Agents10\\n'\n",
      " 'Everything in Little Plan, Plus:\\n'\n",
      " 'MS Teams Chatbot Platform*ChatGPT AI IntegrationConfigure AI Chatbot '\n",
      " 'TrainingTrigger Actions on Unusual AI Chat SenariosRole-based Access '\n",
      " 'ControlsAPI Integration in ChatflowsZapier IntegrationSimplybook '\n",
      " 'IntegrationZoho Commerce Integration50+ Integrations\\n'\n",
      " 'MS Teams Chatbot Platform*\\n'\n",
      " 'ChatGPT AI Integration\\n'\n",
      " 'Configure AI Chatbot Training\\n'\n",
      " 'Trigger Actions on Unusual AI Chat Senarios\\n'\n",
      " 'Role-based Access Controls\\n'\n",
      " 'API Integration in Chatflows\\n'\n",
      " 'Zapier Integration\\n'\n",
      " 'Simplybook Integration\\n'\n",
      " 'Zoho Commerce Integration\\n'\n",
      " '50+ Integrations\\n'\n",
      " 'Emperor Plan\\n'\n",
      " 'For Enterprise\\n'\n",
      " 'Custom Pricing\\n'\n",
      " 'MessagesAs per NeedConversationsAs per NeedChatbotUnlimitedAgentsUnlimited\\n'\n",
      " 'MessagesAs per Need\\n'\n",
      " 'ConversationsAs per Need\\n'\n",
      " 'AgentsUnlimited\\n'\n",
      " 'Everything in King Plan, Plus:',\n",
      " 'For Enterprise\\n'\n",
      " 'Custom Pricing\\n'\n",
      " 'MessagesAs per NeedConversationsAs per NeedChatbotUnlimitedAgentsUnlimited\\n'\n",
      " 'MessagesAs per Need\\n'\n",
      " 'ConversationsAs per Need\\n'\n",
      " 'AgentsUnlimited\\n'\n",
      " 'Everything in King Plan, Plus:\\n'\n",
      " 'Chatbot PlatformsInstagramWechatLineViberSMSGoogle My BusinessSlackAI Bot '\n",
      " 'Training onGoogle SheetGoogle DriveYoutube/Custom '\n",
      " 'VideosRSSDropboxTextCustomized As Per Your NeedAdvanced Analytics & '\n",
      " 'ReportingExtensive IntegrationsRemove BotPenguin BrandingRule Based Chat '\n",
      " \"RoutingCustom Campaigns & TrackingFB E-commerce IntegrationWe'll build it \"\n",
      " 'for youAdvanced Security Modules60+ Integrations\\n'\n",
      " 'Chatbot PlatformsInstagramWechatLineViberSMSGoogle My BusinessSlack\\n'\n",
      " 'AI Bot Training onGoogle SheetGoogle DriveYoutube/Custom '\n",
      " 'VideosRSSDropboxText\\n'\n",
      " 'AI Bot Training on\\n'\n",
      " 'Customized As Per Your Need\\n'\n",
      " 'Advanced Analytics & Reporting\\n'\n",
      " 'Extensive Integrations\\n'\n",
      " 'Remove BotPenguin Branding\\n'\n",
      " 'Rule Based Chat Routing\\n'\n",
      " 'Custom Campaigns & Tracking\\n'\n",
      " 'FB E-commerce Integration\\n'\n",
      " \"We'll build it for you\\n\"\n",
      " 'Advanced Security Modules']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(splits[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1058, which is longer than the specified 1000\n",
      "Created a chunk of size 1050, which is longer than the specified 1000\n",
      "Created a chunk of size 1305, which is longer than the specified 1000\n",
      "Created a chunk of size 1629, which is longer than the specified 1000\n",
      "Created a chunk of size 1273, which is longer than the specified 1000\n",
      "Created a chunk of size 1004, which is longer than the specified 1000\n",
      "Created a chunk of size 1475, which is longer than the specified 1000\n",
      "Created a chunk of size 1457, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "from langchain.docstore.document import Document\n",
    "# texts = split_with_character_text_splitter.create_documents([text])\n",
    "docs = split_with_character_text_splitter(content)\n",
    "documents = []\n",
    "for doc in docs:\n",
    "    documents.append(Document(page_content=doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing vector store loaded.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS \n",
    "\n",
    "def create_new_vectorstore():\n",
    "   \n",
    "    # Create a new vector store from documents\n",
    "    vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "    vectorstore.save_local(\"vectorstore\")\n",
    "    print(\"New vector store created and saved locally.\")\n",
    "    return vectorstore\n",
    "\n",
    "\n",
    "def load_existing_vectorstore():\n",
    "    # Load an existing vector store\n",
    "    vectorstore = FAISS.load_local(\"vectorstore\", embeddings, allow_dangerous_deserialization=True)\n",
    "    print(\"Existing vector store loaded.\")\n",
    "    return vectorstore\n",
    "\n",
    "choice = input(\"Would you like to (1) create a new vector database or (2) load an existing one? Enter 1 or 2: \")\n",
    "    \n",
    "if choice == '1':\n",
    "    vectorstore=create_new_vectorstore()\n",
    "elif choice == '2':\n",
    "    vectorstore = load_existing_vectorstore()\n",
    "else:\n",
    "    print(\"Invalid choice. Please enter 1 or 2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\"What is BotPenguin?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This will remove the manual process of creating any White-Labeled or Reseller account.\n",
      "Video Link:https://drive.google.com/drive/folders/19KilDEeSwU5Bz05t5e1SU6O4tWiYwUxF?usp=drive_link\n",
      "Help Link:https://help.botpenguin.com/partner-documentation/botpenguin-partner-onboarding/signup-as-a-botpenguin-partner\n",
      "✅MS Teams\n",
      "A New Platform for Bot Creation has been added in BotPenguin now our customers are also able to add Bots for MS Teams.Ability to train the bot with the AI CapabilitiesAbility to to access inboxAbility to access setting related to the bot.\n",
      "A New Platform for Bot Creation has been added in BotPenguin now our customers are also able to add Bots for MS Teams.\n",
      "Ability to train the bot with the AI Capabilities\n",
      "Ability to to access inbox\n",
      "Ability to access setting related to the bot.\n",
      "✅Zoho Commerce Integration\n"
     ]
    }
   ],
   "source": [
    "print(retrieved_docs[4].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Write with simple language in Paul Graham style. Write at least least 5 sentences.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(model_name=\"gpt-4-0125-preview\", temperature=0)\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BotPenguin is an omnichannel platform that allows clients to be present on all social media platforms 24/7, 365 days a year. It helps in solving customer queries easily and efficiently. With a user-friendly interface, BotPenguin does not require technical knowledge or coding skills to set up chatbots. As a BotPenguin Partner, you can earn high incentives and have the flexibility to set your pricing. The platform integrates with popular CRM systems like Zoho, Agile CRM, and Bitrix24, making it easy to handle customer support in one place.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"What is BotPenguin?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access Management refers to the process of controlling and managing user access to certain features, functionalities, or data within a system or platform. This includes setting permissions, roles, and restrictions for different users or user groups to ensure that they only have access to the resources they need. Access Management also involves handling authentication, authorization, and user roles to maintain security and privacy within the system. It allows administrators to regulate who can view, edit, or delete specific information or perform certain actions within the platform. Overall, Access Management is crucial for maintaining data integrity, security, and user experience."
     ]
    }
   ],
   "source": [
    "for chunk in rag_chain.stream(\"What is Access Management?\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': [Document(page_content='Activated plans visible to customers; archived plans remain hidden.\\nFeature availability dynamically controlled via toggles.\\nManage consumption limits and pricing for add-ons.\\nInvoices now include detailed plan and settlement information.\\nCustomer and Agency Management\\nAgencies must configure billing details and can now view and download invoices.Settlement handled based on message/conversation consumption or days used.New tabs for subscriptions, billing, and configurations added.Agencies can purchase plans and add-ons directly from their dashboard.Retention period defined for customer accounts after agency plan expiry.Renewal emails and consumption notifications implemented.\\nAgencies must configure billing details and can now view and download invoices.\\nSettlement handled based on message/conversation consumption or days used.\\nNew tabs for subscriptions, billing, and configurations added.\\nAgencies can purchase plans and add-ons directly from their dashboard.'),\n",
       "  Document(page_content='Set up tax details, display names, types, and applicability.\\nManage currencies, payment gateways, and payment grace periods.\\nAdd and configure plan details, features, integrations, and restrictions.\\nActivate, deactivate, archive, and manage plans and add-ons.\\nOverride and manage payment transactions and invoices.\\nConfigure and handle default, upgraded, and downgraded plans, including grace periods.\\nPlan and Add-On Management\\nDefault free plan handling removed; paid plans can be set as default.Activated plans visible to customers; archived plans remain hidden.Feature availability dynamically controlled via toggles.Manage consumption limits and pricing for add-ons.Invoices now include detailed plan and settlement information.\\nDefault free plan handling removed; paid plans can be set as default.\\nActivated plans visible to customers; archived plans remain hidden.\\nFeature availability dynamically controlled via toggles.\\nManage consumption limits and pricing for add-ons.'),\n",
       "  Document(page_content='1 Integration with Third-Party Services\\n2 Enhancing Functionality\\n3 Streamlining Workflows\\n4 Data Synchronization, etc.\\n✅Raise A Ticket Feature\\nImplementing a \"raise a ticket\" feature contributes to a more organized and efficient customer support process, ultimately leading to improved user satisfaction and a positive overall experience with the web apps\\n✅DB Migration to Atlas Cloud\\nMigrating a database to MongoDB Atlas Cloud brings scalability, automated backups, and high availability, ensuring seamless data management. With security features like encryption and network isolation, Atlas enhances data protection.'),\n",
       "  Document(page_content='We have implemented a toggle button for the Super Administrator, empowering them to activate or deactivate ChatGPT functionality for any White Label (WL) Agency as needed.\\nWhite Label Agencies now have the capability to seamlessly integrate their proprietary ChatGPT keys through the Configuration tab. This empowers their users to access ChatGPT components for free messaging functionalities.\\nNote: If ChatGPT is off for the agency then for that Agency customer ChatGPT component and AI Setting will be hidden.\\n✅FB & WA meta Oauth whitelabel configuration\\nThe Super Administrator now possesses the capability to grant access to any White Label (WL) Agency for the activation of Facebook bots and creation of WhatsApp functionalities directly from the meta. Within the agency details section, we have implemented two toggle buttons, allowing the Super Administrator to enable or disable these features for a specific agency at their discretion.'),\n",
       "  Document(page_content='New tabs for subscriptions, billing, and configurations added.\\nAgencies can purchase plans and add-ons directly from their dashboard.\\nRetention period defined for customer accounts after agency plan expiry.\\nRenewal emails and consumption notifications implemented.\\nEnhancements and Fixes\\nLocalized new tabs and sections for agencies.Permissions updated for new subscription tabs and roles.Super Admins can now configure integration keys and manage agency features and restrictions effectively.\\nLocalized new tabs and sections for agencies.\\nPermissions updated for new subscription tabs and roles.\\nSuper Admins can now configure integration keys and manage agency features and restrictions effectively.\\nThese updates ensure seamless management of plans, taxes, and subscriptions, enhancing the overall user experience for Super Admins, agencies, and their customers.'),\n",
       "  Document(page_content='✅AI search added from backend for Websites, Files, and FAQs\\nAI search is a powerful tool that can be used to improve websites, files, and FAQs in a number of ways. By improving the user experience, increasing engagement, improving customer satisfaction, reducing costs, and improving security, AI search can help businesses to achieve their goals. By adding search from backend our bot response speed have positive impacts.\\n✅Plan name is editable from the panel for Whitelabel Agency\\nThe plan name edit functionality is a simple but powerful feature that can have a number of positive benefits for both businesses and their customers.\\nVicente AI issue patch fixedSanesa issue fixedPreview text to be changed to TestReset Password issue fixed for whitelabels and mobile app\\nVicente AI issue patch fixed\\nSanesa issue fixed\\nPreview text to be changed to Test\\nReset Password issue fixed for whitelabels and mobile app')],\n",
       " 'question': 'What is Access Management?',\n",
       " 'answer': 'Access Management refers to the process of controlling and managing user access to certain features, functionalities, or data within a system or platform. It involves setting permissions, roles, and restrictions to ensure that users only have access to the resources they need to perform their tasks effectively. Access Management also includes features like toggles, activation, deactivation, and configuration settings that allow administrators to control and monitor user access in a secure and efficient manner. It plays a crucial role in maintaining data security, privacy, and overall system integrity by preventing unauthorized access and ensuring that users have the appropriate level of access based on their roles and responsibilities.'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain_from_docs)\n",
    "\n",
    "rag_chain_with_source.invoke(\"What is Access Management?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_to_markdown(data):\n",
    "    markdown_output = (\n",
    "        f\"Question:{data['question']}\\n\\nAnswer:\\n{data['answer']}\"#\\n\\nSources:\\n\\n\"\n",
    "    )\n",
    "    for i, doc in enumerate(data[\"context\"], start=1):\n",
    "        page_content = doc.page_content.split(\"\\n\")[\n",
    "            0\n",
    "        ] \n",
    "    return markdown_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Question:What are various plans avilable at BotPenguin?\n",
       "\n",
       "Answer:\n",
       "At BotPenguin, there are different plans available for users. The plans include the Baby Plan, King Plan, and more. The Baby Plan is like a trial with no time limit, allowing users to take their time to size up. The King Plan allows users to create chatbots for websites, Facebook, and Telegram, along with other features. Additionally, there are options to add more agents at additional charges. Users can also create custom plans for their customers and manage them accordingly."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "res = rag_chain_with_source.invoke(\"What are various plans avilable at BotPenguin?\")\n",
    "display(Markdown(format_to_markdown(res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(q):\n",
    "    res = rag_chain_with_source.invoke(q)\n",
    "    return display(Markdown(format_to_markdown(res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Question:How can i use BotPenguin in my Business?\n",
       "\n",
       "Answer:\n",
       "To use BotPenguin in your business, you can start by becoming a partner through the BotPenguin Partnership Program. Depending on your preference and business model, you can choose to be an affiliate partner, white label partner, or implementation partner. Once you have partnered with BotPenguin, you can integrate the platform into your business by following the provided guidelines and steps. This will allow you to leverage the benefits of BotPenguin's omnichannel platform, easy-to-use chatbot setup, and seamless integration with popular CRM platforms. By using BotPenguin in your business, you can enhance customer support, increase efficiency, and drive growth."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ask(\"How can i use BotPenguin in my Business?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Question:How can i contact with Botpenguin, provide Contact Details if possible?\n",
       "\n",
       "Answer:\n",
       "You can contact BotPenguin through their headquarters in Mohali, India, located at 303, C-184, Third Floor, Sector 75, Mohali, Punjab 160071. Additionally, you can reach their sales office in Illinois, USA, at 2323 N Pulaski Rd, Chicago, IL 60639, United States. For more information, you can visit their website at https://help.botpenguin.com/product-updates/release-updates/april-24-releases."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ask(\"How can i contact with Botpenguin, provide Contact Details if possible?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Question:What are the various ratings that Botpenguin have obtained?\n",
       "\n",
       "Answer:\n",
       "BotPenguin has received positive ratings on platforms like G2, Capterra, Trustpilot, and Good Firms. Customers have praised the platform for its ability to execute in a timely manner, its practicality for sales and marketing objectives, and its robust support for all queries and issues. The platform has been rated highly for its ease of use, integrations with popular platforms, and transparency in its incentive structure. Overall, BotPenguin has garnered positive feedback from customers and partners across various platforms."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ask(\"What are the various ratings that Botpenguin have obtained?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
